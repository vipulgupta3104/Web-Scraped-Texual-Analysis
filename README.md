# Web-Scraped Textual Analysis (Text Miner)

This project extracts and analyzes textual content from online articles using Natural Language Processing (NLP) techniques. It performs sentiment analysis, readability scoring, and feature extraction from raw web data.

## ğŸ“Œ Project Overview

- Built a Python-based NLP pipeline to perform **text mining** on web articles.
- Scraped text content from online sources using **requests** and **BeautifulSoup**.
- Processed and analyzed the text with **nltk**, applying various NLP techniques.
- Extracted features such as polarity, subjectivity, FOG index, complex word count, and average word length.
- Stored the results in a structured **CSV** format for downstream tasks.

## ğŸ§° Tech Stack & Tools

- Python  
- Requests, BeautifulSoup  
- NLTK  
- Pandas  
- Jupyter Notebook

## ğŸ” Key Features

- Web scraping of raw HTML content
- Text cleaning and preprocessing (tokenization, stopword removal, etc.)
- Sentiment analysis using polarity and subjectivity
- Readability scoring using the **FOG Index**
- Keyword and feature extraction (e.g., complex words, personal pronouns)
- Export of processed results to structured CSV format

## ğŸ“ Workflow

1. **Scrape** content from target URLs
2. **Clean and tokenize** the raw text
3. **Analyze** sentiment and readability
4. **Extract features** for further insights
5. **Save output** as structured CSV

## ğŸš€ How to Run

1. Clone the repository  
   `git clone https://github.com/vipulgupta3104/Web-Scraped-Texual-Analysis.git`

2. Navigate to the directory  
   `cd Web-Scraped-Texual-Analysis`

3. Complete the requirements present in requirements.txt
   
4. Open the notebook in Jupyter  
   `Main.ipynb`

5. Run all cells to:
   - Input URLs
   - Scrape and clean data
   - Generate sentiment and readability scores
   - Export results to CSV

## ğŸ“„ License

This project is intended for educational and research use. Feel free to modify and expand.

---
